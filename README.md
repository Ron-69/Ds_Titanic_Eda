# üö¢ Projeto de Data Science: EDA Avan√ßada e Pr√©-processamento - Dataset Titanic

## 1. Vis√£o Geral do Projeto

Este projeto demonstra um pipeline de **An√°lise Explorat√≥ria de Dados (EDA)** avan√ßada e **Pr√©-processamento** para o cl√°ssico *dataset* Titanic. O objetivo principal √© transformar dados brutos e complexos em um formato pronto para modelagem preditiva, focando na supera√ß√£o de desafios comuns em Data Science, como valores ausentes (`NaN`), *outliers* e vari√°veis categ√≥ricas de alta cardinalidade.

### üéØ Objetivo Principal

Prever a **Sobreviv√™ncia** (`Survived` - Vari√°vel Target Bin√°ria) dos passageiros, construindo *features* robustas baseadas em *insights* estat√≠sticos e de neg√≥cio.

### üõ†Ô∏è Tecnologias e Ferramentas

| Categoria | Ferramenta | Uso no Projeto |
| :--- | :--- | :--- |
| **Linguagem** | **Python** | Linguagem de programa√ß√£o principal. |
| **Ambiente** | **VS Code & Jupyter Notebooks** | Fluxo de trabalho profissional e reprodut√≠vel. |
| **Manipula√ß√£o** | **Pandas & NumPy** | Carregamento, limpeza e transforma√ß√£o de dados. |
| **Visualiza√ß√£o** | **Seaborn & Matplotlib** | EDA para identificar distribui√ß√µes, *outliers* e rela√ß√µes. |
| **Estat√≠stica** | **SciPy** | Testes estat√≠sticos r√°pidos (assimetria, testes t, etc.). |
| **Controle de Vers√£o**| **Git** | Rastreamento de altera√ß√µes e colabora√ß√£o (branch `main`). |

---

## 2. An√°lise Explorat√≥ria de Dados (EDA)

A EDA foi conduzida com foco em traduzir caracter√≠sticas complexas em *features* preditivas, utilizando o rigor estat√≠stico.

### 2.1. An√°lise de Qualidade de Dados e Estat√≠sticas Sum√°rias

A primeira etapa envolveu o uso de **`df.info()`** e **`df.describe(include='all')`** para quantificar a qualidade e a distribui√ß√£o inicial dos dados.

| Coluna | Descoberta Estat√≠stica Chave | Implica√ß√µes para o Pr√©-processamento |
| :--- | :--- | :--- |
| **`Survived`**| Taxa de sobreviv√™ncia geral de **38.4%** (`M√©dia = 0.3838`). | Indica um desbalanceamento moderado de classes. |
| **`Age`** | **20% de valores ausentes** (714 de 891). M√©dia (29.7) e Mediana (28.0) pr√≥ximas. | Ser√° imputada com a **Mediana**, pois √© mais robusta a *outliers*. |
| **`Fare`** | **Forte assimetria √† direita** (M√©dia $32.20 vs. Mediana $14.45). Max √© $512. | **Transforma√ß√£o logar√≠tmica** ser√° obrigat√≥ria para mitigar a assimetria e o impacto dos *outliers*. |
| **`Cabin`** | **77% de valores ausentes** (204 de 891). | A coluna bruta ser√° transformada em uma *feature* **bin√°ria** (`Has_Cabin`). |
| **`Embarked`** | Apenas **2 valores ausentes**. | Imputa√ß√£o simples pela **Moda** (Porto mais frequente). |
| **`Pclass`** | **Mediana = 3.0**, confirmando que a 3¬™ classe era a mais populosa. | Confirma ser uma vari√°vel altamente preditiva (status social). 

### üí° Insights Chave da EDA Visual

A an√°lise gr√°fica das rela√ß√µes entre as vari√°veis confirmou as hip√≥teses iniciais e orientou a Engenharia de Features:

1.  **Status Social e G√™nero:** A sobreviv√™ncia foi fortemente influenciada pela `Pclass` e `Sex`.
    
    ![Taxa de Sobreviv√™ncia por G√™nero e Classe de Bilhete](notebooks/plots/survival_rate_sex_pclass.png)

2.  **Idade e Outliers:** O Boxplot da Idade mostrou a distribui√ß√£o em rela√ß√£o √† sobreviv√™ncia.
    
    ![Distribui√ß√£o da Idade por Sobreviv√™ncia](notebooks/plots/age_distribution_boxplot.png)

3.  **Tarifa (Fare):** A alta assimetria na tarifa foi confirmada visualmente, o que justificou a transforma√ß√£o logar√≠tmica.
    
    ![Distribui√ß√£o Bruta da Tarifa (Fare)](notebooks/plots/fare_distribution_histogram.png)

---|

### 2.2. Engenharia de Features Chave (Feature Engineering)

Ap√≥s a imputa√ß√£o de nulos (`Age` com Mediana, `Embarked` com Moda) e a transforma√ß√£o logar√≠tmica de `Fare` (corrigindo a assimetria), as seguintes *features* preditivas foram criadas, gerando *insights* estat√≠sticos robustos:

#### üí° Resultados das Features Criadas

| Feature | Descri√ß√£o | Taxa de Sobreviv√™ncia (M√©dia) | Insight Chave |
| :--- | :--- | :--- | :--- |
| **`Has_Cabin` (1)**| Passageiro com cabine registrada | **66.67%** | Confirma que a posse de cabine √© um poderoso preditor de status e sobreviv√™ncia (Taxa 2x maior que quem n√£o tinha). |
| **`IsAlone` (0)** | Passageiro em grupo/fam√≠lia | **50.57%** | Passageiros que viajavam em grupo tiveram chance de sobreviv√™ncia significativamente maior do que os que viajavam sozinhos (30.35%). |
| **`Title` (Mrs)** | T√≠tulo de Casada | **79.37%** | O `Title` provou ser o preditor mais forte, com `Mrs` e `Miss` apresentando as taxas mais altas. `Mr` (homem adulto) possui a taxa mais baixa (15.67%). |

---

## 3. Conclus√µes e Plano de A√ß√£o (Pr√≥ximos Passos)

### üí° Status das Fases

* ‚úÖ **Imputa√ß√£o de Dados:** `Age` e `Embarked` foram tratados com sucesso.
* ‚úÖ **Transforma√ß√£o de Dados:** `Fare` foi transformada via `log1p` para normaliza√ß√£o.
* ‚úÖ **Engenharia de Features:** `Has_Cabin`, `IsAlone`, `FamilySize` e `Title` foram criadas.

## 3. Conclus√µes e Plano de A√ß√£o (Pr√≥ximos Passos)

### üí° Status da Prepara√ß√£o de Dados

A fase de prepara√ß√£o de dados foi finalizada, garantindo que o dataset esteja 100% num√©rico e pronto para o treinamento de modelos.

### üìä Codifica√ß√£o e Sele√ß√£o Final de Features

| A√ß√£o | Resultado | Dimens√µes Finais |
| :--- | :--- | :--- |
| **One-Hot Encoding (OHE)** | Aplicado em `Sex`, `Embarked`, `Title` e `Pclass`. | +8 Novas colunas bin√°rias criadas. |
| **Sele√ß√£o Final** | Colunas originais redundantes (`Name`, `Ticket`, `Cabin`, `SibSp`, `Parch`, `Fare` original) removidas. | DataFrame final com **15 colunas** (`Survived` + 14 Features). |
| **Divis√£o (Train/Test)** | Dados divididos em 80% Treino e 20% Teste. | Treino (`X_train`): **712 linhas** (80%). |

## 4. Resultados Finais e Conclus√£o

A fase final do projeto consistiu no treinamento e avalia√ß√£o de dois modelos de Classifica√ß√£o no conjunto de teste (20% dos dados).

### üèÜ Desempenho dos Modelos

| Modelo | Acur√°cia (Accuracy) | Precision (Classe 1 - Sobreviveu) | Recall (Classe 1 - Sobreviveu) |
| :--- | :--- | :--- | :--- |
| **Regress√£o Log√≠stica (Baseline)**| **0.8156 (81.56%)** | **0.79** | 0.71 |
| **Random Forest Classifier** | 0.8045 (80.45%) | 0.75 | **0.74** |

### 4.1. Otimiza√ß√£o e Valida√ß√£o do Random Forest via Grid Search

Para tentar superar a acur√°cia de **81.56%** obtida pela Regress√£o Log√≠stica (*baseline*), o modelo **Random Forest Classifier** foi submetido a um processo de **Otimiza√ß√£o de Hiperpar√¢metros** utilizando **Grid Search com Valida√ß√£o Cruzada (CV=5)**.

O objetivo do Grid Search √© testar sistematicamente um vasto espa√ßo de par√¢metros para encontrar a combina√ß√£o ideal que maximize o desempenho (acur√°cia) e melhore a capacidade de generaliza√ß√£o do modelo. 

| Hiperpar√¢metro | Espa√ßo de Busca |
| :--- | :--- |
| `n_estimators` | [50, 100, 200] (N√∫mero de √°rvores) |
| `max_depth` | [5, 8, 15, None] (Profundidade da √°rvore) |
| `min_samples_split` | [2, 5, 10] (M√≠nimo de amostras para dividir) |
| `min_samples_leaf` | [1, 2, 4] (M√≠nimo de amostras em uma folha) |

#### Resultados da Otimiza√ß√£o

| M√©trica | Valor | Par√¢metros Otimizados |
| :--- | :--- | :--- |
| **Melhor Acur√°cia (Cross-Validation)**| **0.8330** | `max_depth=15`, `min_samples_leaf=2`, `n_estimators=100` |

Apesar de atingir 83.30% de acur√°cia durante a valida√ß√£o cruzada, o modelo otimizado obteve **81.01%** no conjunto de teste independente, confirmando que a Regress√£o Log√≠stica manteve a melhor *performance* geral.

### Conclus√£o Final do Projeto ap√≥s otimiza√ß√£o do modelo Random Forest


1.  **Modelo Vencedor:** A **Regress√£o Log√≠stica** √© o modelo escolhido. Sua *performance* superior (81.56% de acur√°cia) demonstra que o relacionamento entre as *features* (especialmente as categ√≥ricas como `Title` e `Has_Cabin`) √© predominantemente **linear** e foi bem capturado pela simplicidade do modelo.
2.  **Efic√°cia da EDA e Engenharia de Features:** O sucesso do modelo simples confirma que a qualidade da **prepara√ß√£o dos dados** foi o fator preditivo mais crucial do projeto.

---
### Conclus√£o do Projeto

1.  **Regress√£o Log√≠stica como Modelo Final:** O modelo *Baseline* (Regress√£o Log√≠stica) demonstrou ser o mais eficiente, atingindo a **maior Acur√°cia geral (81.56%)** e a **maior Precis√£o (79%)** na previs√£o de sobreviv√™ncia. Isso indica que, quando o modelo prev√™ que um passageiro sobreviveu, ele est√° mais certo do que o Random Forest.
2.  **Import√¢ncia do Pr√©-processamento:** O sucesso dos modelos, mesmo de um modelo linear simples como a Regress√£o Log√≠stica, demonstra a efic√°cia da **Engenharia de Features** (como `Title` e `Has_Cabin`) na transforma√ß√£o dos dados brutos em preditores robustos.
3.  **Sugest√£o de Continuidade:** Para tentar superar esta *baseline*, os pr√≥ximos passos envolveriam **Otimiza√ß√£o de Hiperpar√¢metros** (Grid Search ou Random Search) nos modelos, especialmente no Random Forest.

---
### üèÜ Desempenho Final dos Modelos

| Modelo | Acur√°cia (Teste) | Precision (Classe 1) | Recall (Classe 1) | Observa√ß√£o |
| :--- | :--- | :--- | :--- | :--- |
| **Regress√£o Log√≠stica (Baseline)**| **0.8156** | **0.79** | 0.71 | Modelo mais simples, atingiu a **maior acur√°cia final** e maior precis√£o para a classe positiva. |
| **Random Forest (Otimizado)** | 0.8101 | 0.80 | 0.68 | N√£o superou a *baseline*. Otimiza√ß√£o alcan√ßou **0.8330** em Cross-Validation, mas perdeu generaliza√ß√£o no teste. |

## üîó Estrutura do Reposit√≥rio

ds_titanic_eda_python/ ‚îú‚îÄ‚îÄ venv/ # Ignorado pelo Git (Ambiente Virtual) ‚îú‚îÄ‚îÄ notebooks/ ‚îÇ ‚îî‚îÄ‚îÄ ds_titanic_eda.ipynb # Notebook principal com EDA e c√≥digo de Feature Engineering ‚îú‚îÄ‚îÄ data/ ‚îÇ ‚îî‚îÄ‚îÄ Titanic-Dataset.csv ‚îú‚îÄ‚îÄ README.md # Este arquivo ‚îú‚îÄ‚îÄ requirements.txt # Lista de depend√™ncias ‚îî‚îÄ‚îÄ .gitignore # Arquivo para exclus√£o de pastas (venv/) e arquivos de sistema